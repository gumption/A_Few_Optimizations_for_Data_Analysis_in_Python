{
 "metadata": {
  "name": "",
  "signature": "sha256:5154ec5cf436b484fb12658942e3de119d4beb48636ff7c703dd114c0027731e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "A few Python optimizations for data analysis"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Motivation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I read [Karolina Alexiou](https://www.linkedin.com/pub/ariadni-karolina-alexiou/34/657/9a3)'s excellent blog post about [The Top Mistakes Developers Make When Using Python for Big Data Analytics](https://www.airpair.com/python/posts/top-mistakes-python-big-data-analytics) with great interest. I have made - and partially learned from - all of the mistakes she warned about. I was particularly eager to try out and extend some of the code snippets she provided to illustrate 2 of the mistakes:\n",
      "\n",
      "* Mistake #1: Reinventing the wheel\n",
      "* Mistake #2: Not tuning for performance\n",
      "\n",
      "I started composing a rather lengthy comment on the blog post, highlighting some aspects I especially appreciated and seeking clarification on others. Whenever I notice myself getting a bit voluminous in a comment on someone else's blog, I typically compose a separate post on my own blog ([Gumption](http://gumption.typepad.com)), and then substitute a link (with a brief summary) on the original blog post. \n",
      "\n",
      "In this instance, it seemed more appropriate - and constructive - to create an IPython Notebook to illustrate and/or investigate some of the issues I was raising in that comment ... and thereby finding some of the clarifications I was initially seeking.\n",
      "\n",
      "I am sharing those investigations here in case they are of interest or use to others ... and because it's been a while since I created and shared an IPython Notebook about [Python and data science](http://nbviewer.ipython.org/github/gumption/Python_for_Data_Science/blob/master/Python_for_Data_Science_all.ipynb)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "On not reinventing the wheel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In Karolina's blog post, she observed\n",
      "\n",
      "> There truly is no reason to get bogged down with solving already-solved problems - spend a few minutes to do a Google search or ask a more experienced developer for suggestions for a data analysis library.\n",
      ">\n",
      "> Incidentally, one such library that's widely used at the time of this writing is Python Pandas. It comes with useful abstractions for dealing with large datasets, a lot of functionality for ETL (extract, transform, load) and good performance. It cuts down developer time by enabling the succinct expression of data transformations and providing functions to load, unify and store data from different sources and formats.\n",
      "\n",
      "I'm a big fan - and regular user - of the open-source [Pandas](http://pandas.pydata.org/) library, and I agree that it has many useful features. There is a bit of overhead to learn how to use the tool _effectively_ - considerably more than the [10 Minutes to Pandas tutorial](http://pandas.pydata.org/pandas-docs/stable/10min.html) might suggest - but it can simplify many common tasks in data analysis.\n",
      "\n",
      "I do find myself resorting to the use of some of [Python's high performance `container` datatypes](https://docs.python.org/2/library/collections.html) for some data analysis tasks, but for all I know, if I just spent longer delving into Pandas, I would find a way to do those tasks directly within Pandas. An example, I suppose, of human performance optimization.\n",
      "\n",
      "Karolina demonstrates the power of Pandas using an example of reading a comma-separated value (CSV) file containing a list of `Products` and the number of `ItemsSold` for each product, and finding the 10 top-selling products and their associated sales volume."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Creating a products and sales CSV file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since I want to experiment with different sizes of product lines, I define a function that generates a CSV file that starts with a header line - in this case, `'Product'` and `'ItemsSold'` - and then proceeds to create `num_products` lines, where each line `i` represents a product named `Product i` that has `i ItemsSold`. I use 1-based indexing rather than 0-based indexing, as that seems more natural.\n",
      "\n",
      "To enable experimentation with different sizes of product lines, I use a file naming scheme that enables me to represent the size in the `filename`, and use that `filename` as the return value of the function.\n",
      "\n",
      "There are a number of generalizations and extensions that could be added - e.g., a parameter for the header names, a generator for the individual product names and/or sales, or using random numbers for the items sold - but I decided to keep it relatively simple."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_products_and_sales_csv_file(filename_prefix='product_and_sales', num_products=10):\n",
      "    filename = '{}_{}.csv'.format(filename_prefix, num_products)\n",
      "    with open(filename, 'w') as f:\n",
      "        f.write('Product,ItemsSold\\n') # ideally, the headers would be passed as argument\n",
      "        for i in xrange(1, num_products + 1): # use 1-based indexing for product names\n",
      "            product = 'Product ' + str(i)\n",
      "            num_items = i\n",
      "            f.write('{},{}\\n'.format(product, num_items))\n",
      "    return filename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = create_products_and_sales_csv_file(num_products=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To verify that the file was created, we can use `%%bash` cell magic to check its size and see the first 10 rows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash -s \"$filename\"\n",
      "wc $1\n",
      "head -10 $1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      11      21     140 product_and_sales_10.csv\n",
        "Product,ItemsSold\n",
        "Product 1,1\n",
        "Product 2,2\n",
        "Product 3,3\n",
        "Product 4,4\n",
        "Product 5,5\n",
        "Product 6,6\n",
        "Product 7,7\n",
        "Product 8,8\n",
        "Product 9,9\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Working with a million-item product line"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To make things a bit more interesting, let's define a product line with a million items ... in which the number of items sold for each product conveniently matches the product line index, e.g., `1` item of `'Product 1'` was sold ... and `1000000` items of `'Product 1000000'` were sold."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = create_products_and_sales_csv_file(num_products=1000000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll use some `%%bash` cell magic to show the size of the file, as well as its first 10 and last 10 lines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash -s \"$filename\"\n",
      "wc $1\n",
      "head -10 $1\n",
      "echo \"...\"\n",
      "tail -n 10 $1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1000001 2000001 21777810 product_and_sales_1000000.csv\n",
        "Product,ItemsSold\n",
        "Product 1,1\n",
        "Product 2,2\n",
        "Product 3,3\n",
        "Product 4,4\n",
        "Product 5,5\n",
        "Product 6,6\n",
        "Product 7,7\n",
        "Product 8,8\n",
        "Product 9,9\n",
        "...\n",
        "Product 999991,999991\n",
        "Product 999992,999992\n",
        "Product 999993,999993\n",
        "Product 999994,999994\n",
        "Product 999995,999995\n",
        "Product 999996,999996\n",
        "Product 999997,999997\n",
        "Product 999998,999998\n",
        "Product 999999,999999\n",
        "Product 1000000,1000000\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Finding the top 10 products, version 1: `defaultdict`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to better facilitate the use of `%timeit` cell magic, I define a function to implement the initial code for finding the top 10 products and sales that Karolina presented as an example of reinventing the wheel. I'll generalize the function slightly, by incorporating a parameter `n` (with a default value of 10) so that we could use the function to find the top `n` products and sales. I also insert a call to [`strip()`](https://docs.python.org/2/library/string.html#string.strip), which I often find useful to eliminate leading or trailing whitespace from lines read in from a text file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict \n",
      "\n",
      "def get_top_products_and_sales_1(filename, n=10):\n",
      "    header_skipped = False \n",
      "    sales = defaultdict(lambda: 0) \n",
      "    with open(filename, 'r') as f: \n",
      "        for line in f: \n",
      "            if not header_skipped: \n",
      "                header_skipped = True \n",
      "                continue \n",
      "            line = line.strip().split(\",\") \n",
      "            product = line[0] \n",
      "            num_sales = int(line[1]) \n",
      "            sales[product] += num_sales \n",
      "    top_n = sorted(sales.items(), key=lambda x:x[1], reverse=True)[:n]\n",
      "    return top_n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I noticed some variations in results when I ran and re-ran cells in this notebook, some of which I suspect are due to variations in the amount of variable memory. To reduce variability due to this cause, I will force a garbage collection using [`gc.collect()`](https://docs.python.org/2/library/gc.html#gc.collect) just before timing the run of each function. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit top10 = get_top_products_and_sales_1(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 4.12 s per loop\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I discovered that the [`%timeit` cell magic](http://ipython.org/ipython-doc/dev/interactive/magics.html#magic-timeit) appears to create its own local scope, so assigning a value to a name (variable) within a `%timeit` cell has no effect on its name outside of that scope."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print top10 # this will generate a NameError due the local scoping of %timeit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'top10' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-9-11b630ece6a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mtop10\u001b[0m \u001b[0;31m# this will generate a NameError due the local scoping of %timeit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'top10' is not defined"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, I will use a separate cell to assign the result of each call to a variant of `get_top_products_and_sales()` to a variable and then print the results. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top10 = get_top_products_and_sales_1(filename)\n",
      "print top10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Product 1000000', 1000000), ('Product 999999', 999999), ('Product 999998', 999998), ('Product 999997', 999997), ('Product 999996', 999996), ('Product 999995', 999995), ('Product 999994', 999994), ('Product 999993', 999993), ('Product 999992', 999992), ('Product 999991', 999991)]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, I'll re-run the cell with `%timeit` without making an assignment, and then make one more call to `get_top10_products_and_sales_1()` to assign the return value to `top10` - without using `%timeit` - to ensure the value will persist, so we can verify the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit get_top_products_and_sales_1(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 4.31 s per loop\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top10 = get_top_products_and_sales_1(filename)\n",
      "print top10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Product 1000000', 1000000), ('Product 999999', 999999), ('Product 999998', 999998), ('Product 999997', 999997), ('Product 999996', 999996), ('Product 999995', 999995), ('Product 999994', 999994), ('Product 999993', 999993), ('Product 999992', 999992), ('Product 999991', 999991)]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Finding the top 10 products, version 2: remove `if` from `for` loop"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before moving on to the version Karolina recommends - using Pandas - I wanted to experiment with a few other variants.\n",
      "\n",
      "One variant is to remove the `if` statement to test for the presence of the header - which is only `True` 0.0001% of the time (in with a file representing a million products) - and use the `readline()` method to skip the headers before the `for` loop.\n",
      "\n",
      "This version seems to slightly increased performance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict \n",
      "\n",
      "def get_top_products_and_sales_2(filename, n=10):\n",
      "    sales = defaultdict(lambda: 0) \n",
      "    with open(filename, 'r') as f:\n",
      "        f.readline() # skip header\n",
      "        for line in f: \n",
      "            line = line.strip().split(\",\") \n",
      "            product = line[0] \n",
      "            num_sales = int(line[1]) \n",
      "            sales[product] += num_sales \n",
      "    top_n = sorted(sales.items(), key=lambda x:x[1], reverse=True)[:n]\n",
      "    return top_n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit get_top_products_and_sales_2(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 4.04 s per loop\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top10 = get_top_products_and_sales_2(filename)\n",
      "print top10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Product 1000000', 1000000), ('Product 999999', 999999), ('Product 999998', 999998), ('Product 999997', 999997), ('Product 999996', 999996), ('Product 999995', 999995), ('Product 999994', 999994), ('Product 999993', 999993), ('Product 999992', 999992), ('Product 999991', 999991)]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Finding the top 10 products, version 3: use a `Counter` rather than `defaultdict(lambda: 0)`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I noticed that using a [`defaultdict(lambda: 0)`](https://docs.python.org/2/library/collections.html#collections.defaultdict) was, in effect, defining a [`Counter`](https://docs.python.org/2/library/collections.html#collections.Counter), and since a `Counter` also offers the [`most_common()`](https://docs.python.org/2/library/collections.html#collections.Counter.most_common) method for returning the N largest values, I thought using a `Counter` might be an intermediate solution to the not reinventing the wheel mistake.\n",
      "\n",
      "This version also seems to offer some increased performance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "\n",
      "def get_top_products_and_sales_3(filename, n=10):\n",
      "    sales = Counter()\n",
      "    with open(filename, 'r') as f:\n",
      "        f.readline() # skip header\n",
      "        for line in f: \n",
      "            line = line.strip().split(\",\") \n",
      "            product = line[0] \n",
      "            num_sales = int(line[1]) \n",
      "            sales[product] += num_sales \n",
      "    top_n = sales.most_common(n)\n",
      "    return top_n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit get_top_products_and_sales_3(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 3.64 s per loop\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top10 = get_top_products_and_sales_3(filename)\n",
      "print top10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Product 1000000', 1000000), ('Product 999999', 999999), ('Product 999998', 999998), ('Product 999997', 999997), ('Product 999996', 999996), ('Product 999995', 999995), ('Product 999994', 999994), ('Product 999993', 999993), ('Product 999992', 999992), ('Product 999991', 999991)]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Finding the top 10 products, version 4: use `csv.reader()` to read and split lines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Python provides a [`csv` module](https://docs.python.org/2/library/csv.html) that enables the reading of CSV files and automatically splitting the comma-separated items into either a list (using [`csv.reader()`](https://docs.python.org/2/library/csv.html#csv.reader)) or a dictionary (using [`csv.DictReader()`](https://docs.python.org/2/library/csv.html#csv.DictReader).\n",
      "\n",
      "I was curious to see how substituting these 2 methods for the manual reading and splitting of lines would affect performance.\n",
      "\n",
      "Here is the version with `csv.reader()`, which offers comparable performance to the prior version, and only saves one line of code (the split()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from collections import Counter\n",
      "\n",
      "def get_top_products_and_sales_4(filename, n=10):\n",
      "    sales = Counter()\n",
      "    with open(filename, 'r') as f:\n",
      "        csv_reader = csv.reader(f, delimiter=',')\n",
      "        _ = csv_reader.next() # skip headers\n",
      "        for fields in csv_reader:\n",
      "            product = fields[0]\n",
      "            num_sales = int(fields[1]) \n",
      "            sales[product] += num_sales \n",
      "    top_n = sales.most_common(n)\n",
      "    return top_n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit get_top_products_and_sales_4(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 3.48 s per loop\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top10 = get_top_products_and_sales_4(filename)\n",
      "print top10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Product 1000000', 1000000), ('Product 999999', 999999), ('Product 999998', 999998), ('Product 999997', 999997), ('Product 999996', 999996), ('Product 999995', 999995), ('Product 999994', 999994), ('Product 999993', 999993), ('Product 999992', 999992), ('Product 999991', 999991)]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Finding the top 10 products, version 5: use `csv.DictReader()` to read and split lines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The use of the `csv.reader()` did not seem to have a significant effect on performance.\n",
      "\n",
      "Here's the version using `csv.DictReader()`, which has a significant negative impact on performance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from collections import Counter\n",
      "\n",
      "def get_top_products_and_sales_5(filename, n=10):\n",
      "    sales = Counter()\n",
      "    with open(filename, 'r') as f:\n",
      "        csv_reader = csv.DictReader(f, delimiter=',')\n",
      "        for fields in csv_reader:\n",
      "            product = fields['Product']\n",
      "            num_sales = int(fields['ItemsSold']) \n",
      "            sales[product] += num_sales \n",
      "    top_n = sales.most_common(n)\n",
      "    return top_n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit get_top_products_and_sales_5(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 8.69 s per loop\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top10 = get_top_products_and_sales_5(filename)\n",
      "print top10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Product 1000000', 1000000), ('Product 999999', 999999), ('Product 999998', 999998), ('Product 999997', 999997), ('Product 999996', 999996), ('Product 999995', 999995), ('Product 999994', 999994), ('Product 999993', 999993), ('Product 999992', 999992), ('Product 999991', 999991)]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Finding the top 10 products, version 6: use `pandas`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function below encapsulates the code that Karolina wrote to demonstrate how much simpler it is to use a `pandas` [`DataFrame`](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.html) for this task, compared with the initial version ... or, for that matter, any of the intermediate solutions I experimented with.\n",
      "\n",
      "It is not only simpler code, but it achieves better performance than any of the other versions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "def get_top_products_and_sales_6(filename, n=10):\n",
      "    data = pd.read_csv(filename) # header is conveniently inferred by default \n",
      "    top_n = data.groupby(\"Product\")[\"ItemsSold\"].sum().order(ascending=False)[:n]\n",
      "    return top_n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit get_top_products_and_sales_6(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 2.79 s per loop\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top10 = get_top_products_and_sales_6(filename)\n",
      "print top10 # pandas provides a way to format output of its DataFrame and Series objects"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Product\n",
        "Product 1000000    1000000\n",
        "Product 999999      999999\n",
        "Product 999998      999998\n",
        "Product 999997      999997\n",
        "Product 999996      999996\n",
        "Product 999995      999995\n",
        "Product 999994      999994\n",
        "Product 999993      999993\n",
        "Product 999992      999992\n",
        "Product 999991      999991\n",
        "Name: ItemsSold, dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Finding the top 10 products, version 7: use GraphLab"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I attended an all-day [Dato (formerly GraphLab)](https://dato.com) training workshop last summer, and was impressed with the [performance optimizations](https://dato.com/products/create/performance.html) that GraphLab Create has made available for their data analysis package, which includes and extends many of the features avialable in pandas. All GraphLab Create functionality is made available through a Python API, but I believe much of the implementation is in C (or some variant).\n",
      "\n",
      "At the time of the workshop, I wasn't able to experiment with many of the features of GraphLab Create (e.g., I was unable to use the [SFrame.apply()](https://dato.com/products/create/docs/generated/graphlab.SFrame.apply.html) method), due to incompatibilities with [Anaconda](https://store.continuum.io/cshop/anaconda/) (a fabulous meta-package, or collection of packages, for doing science, math, engineering and data analysis in Python), but it appears the latest version (1.2.1) is compatible with Anaconda.\n",
      "\n",
      "Just to round things out, I'll define and time a version of `get_top_products_and_sales` using a GraphLab Create [`SFrame`](https://dato.com/products/create/docs/generated/graphlab.SFrame.html), which extends the functionality - with performance optimizations - of a pandas DataFrame. One of the extensions is a built-in method for computing the [`topk`](https://dato.com/products/create/docs/generated/graphlab.SFrame.topk.html) elements of an `SFrame`, which not only further simplifies the code (no need to use `groupby`, `sum` or `order` methods), but achieves a significant increase in performance over the `pandas DataFrame` version."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import graphlab as gl\n",
      "\n",
      "def get_top_products_and_sales_7(filename, n=10):\n",
      "    data = gl.SFrame.read_csv(filename) # header is conveniently inferred by default \n",
      "    top_n = data.topk(\"ItemsSold\", n) # GraphLab Create includes a built-in method for finding topk\n",
      "    return top_n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit get_top_products_and_sales_7(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Start server at: ipc:///tmp/graphlab_server-33241 - Server binary: /anaconda/lib/python2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1422374964.log\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] GraphLab Server Version: 1.2.1\n"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 100 lines in 0.204161 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 100 lines in 0.204161 secs."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 1000000 lines in 0.457372 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 1000000 lines in 0.457372 secs."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 100 lines in 0.217378 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 100 lines in 0.217378 secs."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "------------------------------------------------------\n",
        "Inferred types from first line of file as \n",
        "column_type_hints=[str,int]\n",
        "If parsing fails due to incorrect types, you can correct\n",
        "the inferred type list above and pass it to read_csv in\n",
        "the column_type_hints argument\n",
        "------------------------------------------------------\n",
        "------------------------------------------------------"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 1000000 lines in 0.462693 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 1000000 lines in 0.462693 secs."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 100 lines in 0.213612 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 100 lines in 0.213612 secs."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Inferred types from first line of file as \n",
        "column_type_hints=[str,int]\n",
        "If parsing fails due to incorrect types, you can correct\n",
        "the inferred type list above and pass it to read_csv in\n",
        "the column_type_hints argument\n",
        "------------------------------------------------------\n",
        "------------------------------------------------------"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 1000000 lines in 0.505631 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 1000000 lines in 0.505631 secs."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 100 lines in 0.21323 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 100 lines in 0.21323 secs."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Inferred types from first line of file as \n",
        "column_type_hints=[str,int]\n",
        "If parsing fails due to incorrect types, you can correct\n",
        "the inferred type list above and pass it to read_csv in\n",
        "the column_type_hints argument\n",
        "------------------------------------------------------\n",
        "------------------------------------------------------"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 1000000 lines in 0.44936 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 1000000 lines in 0.44936 secs."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Inferred types from first line of file as \n",
        "column_type_hints=[str,int]\n",
        "If parsing fails due to incorrect types, you can correct\n",
        "the inferred type list above and pass it to read_csv in\n",
        "the column_type_hints argument\n",
        "------------------------------------------------------\n",
        "1 loops, best of 3: 1.18 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top10 = get_top_products_and_sales_7(filename)\n",
      "print top10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 100 lines in 0.205387 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 100 lines in 0.205387 secs."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file /Users/joem/Notebooks/product_and_sales_1000000.csv"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 1000000 lines in 0.460181 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 1000000 lines in 0.460181 secs."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "------------------------------------------------------\n",
        "Inferred types from first line of file as \n",
        "column_type_hints=[str,int]\n",
        "If parsing fails due to incorrect types, you can correct\n",
        "the inferred type list above and pass it to read_csv in\n",
        "the column_type_hints argument\n",
        "------------------------------------------------------\n",
        "+-----------------+-----------+\n",
        "|     Product     | ItemsSold |\n",
        "+-----------------+-----------+\n",
        "| Product 1000000 |  1000000  |\n",
        "|  Product 999999 |   999999  |\n",
        "|  Product 999998 |   999998  |\n",
        "|  Product 999997 |   999997  |\n",
        "|  Product 999996 |   999996  |\n",
        "|  Product 999995 |   999995  |\n",
        "|  Product 999994 |   999994  |\n",
        "|  Product 999993 |   999993  |\n",
        "|  Product 999992 |   999992  |\n",
        "|  Product 999991 |   999991  |\n",
        "+-----------------+-----------+\n",
        "[10 rows x 2 columns]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "On not tuning for performance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The third common mistake that Python programmers conducting data analysis that Karolina warned about was not striving to optimize code _performance_, vs. optimizing code _simplicity_ (though, as shown above, seeking the latter goal can sometimes also achieve the former goal).\n",
      "\n",
      "The example in this section of the post focuses on the use of [`cython`](http://cython.org/), a library of C extensions for Python. Unlike the preceding section, I have no experience in using Cython, but her examples are sufficiently compelling to motivate me to seek out opportunities for applying Cython optimizations in my future work."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Summing numbers _without_ `cython`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Karolina presented a function to sum the integers from 0 to 99999 and return the sum using a `for` loop in Python. I modified the function below to generalize the function to accept a parameter `n` and shift the series by 1 (to sum the ingegers from 1 to `n`).\n",
      "\n",
      "The differences between this function and its equivalent in `cython` still serve to show the orders of magnitude improvement in performance by using `cython`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sum_uncythonized(n): \n",
      "    a = 0 \n",
      "    for i in range(1, n + 1): \n",
      "        a += i\n",
      "    return a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Summing numbers _with_ `cython`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython \n",
      "def sum_cythonized(n): \n",
      "    cdef long a = 0 # this directive defines a type for the variable\n",
      "    cdef int i = 0 \n",
      "    for i in range(1, n + 1): \n",
      "        a += i \n",
      "    return a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit sum_uncythonized(100000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 6.48 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit sum_cythonized(100000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 loops, best of 3: 59.8 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Using iterators and generators (or `xrange` vs. `range`)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the relatively few optimizations I covered in my [Python for Data Science](http://nbviewer.ipython.org/github/gumption/Python_for_Data_Science/blob/master/Python_for_Data_Science_all.ipynb) IPython Notebook was using [`iterators`](https://docs.python.org/2/library/stdtypes.html#iterator-types) or [`generators`](https://docs.python.org/2/library/stdtypes.html#generator-types) wherever possible.\n",
      "\n",
      "Although I now believe it is not, strictly speaking, an example of either an `iterator` or `generator`, [`xrange`](https://docs.python.org/2/library/functions.html#xrange) is a special - but frequently occuring - case of the type of optimization that can be gained in using a method or function that produces one sequence item at a time rather than generating the entire sequence, e.g., as happens when using [`range`](https://docs.python.org/2/library/functions.html#range). This is more of a memory optimization than a speed optimization, but when working with \"big data\", memory optimizations can be an important consideration.\n",
      "\n",
      "In any case, I defined variants of the 2 functions above using `xrange` instead of `range`. There appears to be some performance improvement in the non-cython version using `xrange` ... but the improvement in the cython version using `xrange` (vs. `range`) seems negligible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sum_uncythonized_2(n): \n",
      "    a = 0 \n",
      "    for i in xrange(1, n + 1): \n",
      "        a += i \n",
      "    return a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython \n",
      "def sum_cythonized_2(n): \n",
      "    cdef long a = 0 # this directive defines a type for the variable\n",
      "    cdef int i = 1 \n",
      "    for i in xrange(1, n): \n",
      "        a += i \n",
      "    return a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit sum_uncythonized_2(100000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 4.93 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gc.collect()\n",
      "%timeit sum_cythonized_2(100000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 loops, best of 3: 60.9 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "My takeaway: still use `iterators` and `generators` wherever possible ... but start looking for  opportunities to use `cython` optimization.\n",
      "\n",
      "I imagine that a `cython` version of `get_top_products_and_sales` - a relatively simple task - would be more complex than any of the Python versions shown above, requiring the definition and use of a [struct](http://docs.cython.org/src/userguide/external_C_code.html#styles-of-struct-union-and-enum-declaration) or pair of [arrays](http://docs.cython.org/src/tutorial/array.html). I may update this notebook - or create another - once I've learned enough to define and experiment with a `cython` version of that function.\n",
      "\n",
      "It will be interesting to see if a direct `cython` implementation would achieve better performance than the `GraphLab Create` version, which takes advantage of previously implemented optimizations based on C."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}